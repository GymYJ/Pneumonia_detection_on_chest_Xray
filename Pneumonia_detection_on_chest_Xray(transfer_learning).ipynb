{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLproject_finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5FwSA_y0RcV",
        "colab_type": "text"
      },
      "source": [
        "# 1. 구글 드라이브 연동\n",
        "Google Colab을 사용하므로 데이터를 구글 드라이브에 올렸다.<br>\n",
        "따라서 데이터를 사용하기 위해 구글 드라이브와 연동한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xM532-kzQsm",
        "colab_type": "code",
        "outputId": "09f2ecfe-0da4-458d-9a8e-63ab83ff72fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZRbJxH40t4C",
        "colab_type": "text"
      },
      "source": [
        "# 2. 데이터 전처리 및 데이터 셋 설정\n",
        "사진의 크기(픽셀)가 같아야 각 층의 커널을 통과한 후 \n",
        "출력 벡터의 크기가 같아지는데 사진의 크기가 모두 다르다.<br>\n",
        "따라서, 사진의 픽셀을 224*224 로 바꾼다.<br>\n",
        "(구글 드라이브에서 변경하려고 하니 오래걸려서 로컬에서 미리 사진의 크기를 바꾸는 전처리를 했다.)<br>\n",
        "<br>\n",
        "그리고 데이터를 각각 training set과 test set으로 나눈다.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWOCnTfw0Lw4",
        "colab_type": "code",
        "outputId": "84a02e45-5bd1-4882-c36b-2be867f508b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob, numpy as np\n",
        "\n",
        "caltech_dir = \"/content/gdrive/My Drive/shuffled_chest_xray2/\"\n",
        "categories = [\"NORMAL\", \"PNEUMONIA\"]\n",
        "nb_classes = len(categories)\n",
        "\n",
        "image_w = 224\n",
        "image_h = 224\n",
        "\n",
        "pixels = image_h * image_w * 3\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for idx, cat in enumerate(categories):\n",
        "    \n",
        "    #one-hot 돌리기.\n",
        "    label = [0 for i in range(nb_classes)]\n",
        "    label[idx] = 1\n",
        "\n",
        "    image_dir = caltech_dir + \"train/\" + cat\n",
        "    files = glob.glob(image_dir+\"/*.jpeg\")\n",
        "    print(cat, \" 파일 길이 : \", len(files))\n",
        "    for i, f in enumerate(files):\n",
        "      img = Image.open(f)\n",
        "      img = img.convert(\"RGB\")\n",
        "      img = img.resize((image_w, image_h))\n",
        "      data = np.asarray(img)\n",
        "\n",
        "      X_train.append(data)\n",
        "      y_train.append(label)\n",
        "\n",
        "      if i % 200 == 0:\n",
        "        print(cat, i, \"/\", len(files), \" : \", f)\n",
        "    \n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "# 셔플\n",
        "shuf = np.arange(X_train.shape[0])\n",
        "np.random.shuffle(shuf)\n",
        "\n",
        "X_train = X_train[shuf]\n",
        "y_train = y_train[shuf]\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for idx, cat in enumerate(categories):\n",
        "    \n",
        "    #one-hot 돌리기.\n",
        "    label = [0 for i in range(nb_classes)]\n",
        "    label[idx] = 1\n",
        "\n",
        "    image_dir = caltech_dir + \"test/\" + cat\n",
        "    files = glob.glob(image_dir+\"/*.jpeg\")\n",
        "    print(cat, \" 파일 길이 : \", len(files))\n",
        "    for i, f in enumerate(files):\n",
        "        img = Image.open(f)\n",
        "        img = img.convert(\"RGB\")\n",
        "        img = img.resize((image_w, image_h))\n",
        "        data = np.asarray(img)\n",
        "\n",
        "        X_test.append(data)\n",
        "        y_test.append(label)\n",
        "\n",
        "        if i % 200 == 0:\n",
        "            print(cat, i, \"/\", len(files), \" : \", f)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "# 셔플\n",
        "shuf = np.arange(X_test.shape[0])\n",
        "np.random.shuffle(shuf)\n",
        "\n",
        "X_test = X_test[shuf]\n",
        "y_test = y_test[shuf]\n",
        "\n",
        "xy = (X_train, y_train, X_test, y_test)\n",
        "print(\"change sets to list ok\")\n",
        "np.save(\"/content/gdrive/My Drive/np/shuffled_data2.npy\", xy)\n",
        "print(\"총 파일 수: \", len(y_train)+len(y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NORMAL  파일 길이 :  4572\n",
            "NORMAL 0 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00022390_000.jpeg\n",
            "NORMAL 200 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00024527_000.jpeg\n",
            "NORMAL 400 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00026181_004.jpeg\n",
            "NORMAL 600 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00027912_005.jpeg\n",
            "NORMAL 800 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00029840_000.jpeg\n",
            "NORMAL 1000 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00015561_008.jpeg\n",
            "NORMAL 1200 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00016861_002.jpeg\n",
            "NORMAL 1400 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00018027_005.jpeg\n",
            "NORMAL 1600 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00019363_004.jpeg\n",
            "NORMAL 1800 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00020928_009.jpeg\n",
            "NORMAL 2000 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00010016_003.jpeg\n",
            "NORMAL 2200 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00011186_000.jpeg\n",
            "NORMAL 2400 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00012228_001.jpeg\n",
            "NORMAL 2600 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00013416_004.jpeg\n",
            "NORMAL 2800 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00014406_001.jpeg\n",
            "NORMAL 3000 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00003591_000.jpeg\n",
            "NORMAL 3200 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00004893_030.jpeg\n",
            "NORMAL 3400 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00006208_000.jpeg\n",
            "NORMAL 3600 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00007407_001.jpeg\n",
            "NORMAL 3800 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00008734_004.jpeg\n",
            "NORMAL 4000 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00000049_001.jpeg\n",
            "NORMAL 4200 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00001437_003.jpeg\n",
            "NORMAL 4400 / 4572  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/NORMAL/00002629_000.jpeg\n",
            "PNEUMONIA  파일 길이 :  4563\n",
            "PNEUMONIA 0 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person504_bacteria_2127.jpeg\n",
            "PNEUMONIA 200 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person564_bacteria_2344.jpeg\n",
            "PNEUMONIA 400 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person62_bacteria_303.jpeg\n",
            "PNEUMONIA 600 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person755_virus_1380.jpeg\n",
            "PNEUMONIA 800 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person881_virus_1531.jpeg\n",
            "PNEUMONIA 1000 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person1866_bacteria_4740.jpeg\n",
            "PNEUMONIA 1200 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person275_virus_565.jpeg\n",
            "PNEUMONIA 1400 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person328_bacteria_1511.jpeg\n",
            "PNEUMONIA 1600 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person387_virus_772.jpeg\n",
            "PNEUMONIA 1800 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person448_bacteria_1937.jpeg\n",
            "PNEUMONIA 2000 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person1253_virus_2129.jpeg\n",
            "PNEUMONIA 2200 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person1343_virus_2316.jpeg\n",
            "PNEUMONIA 2400 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person1442_bacteria_3726.jpeg\n",
            "PNEUMONIA 2600 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person152_bacteria_724.jpeg\n",
            "PNEUMONIA 2800 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person1641_bacteria_4350.jpeg\n",
            "PNEUMONIA 3000 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/00014361_000.jpeg\n",
            "PNEUMONIA 3200 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/00018224_014.jpeg\n",
            "PNEUMONIA 3400 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/00023138_009.jpeg\n",
            "PNEUMONIA 3600 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person1022_virus_1712.jpeg\n",
            "PNEUMONIA 3800 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/person1142_bacteria_3086.jpeg\n",
            "PNEUMONIA 4000 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/00000032_012.jpeg\n",
            "PNEUMONIA 4200 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/00006024_012.jpeg\n",
            "PNEUMONIA 4400 / 4563  :  /content/gdrive/My Drive/shuffled_chest_xray2/train/PNEUMONIA/00011460_043.jpeg\n",
            "NORMAL  파일 길이 :  1141\n",
            "NORMAL 0 / 1141  :  /content/gdrive/My Drive/shuffled_chest_xray2/test/NORMAL/00003840_001.jpeg\n",
            "NORMAL 200 / 1141  :  /content/gdrive/My Drive/shuffled_chest_xray2/test/NORMAL/00008593_005.jpeg\n",
            "NORMAL 400 / 1141  :  /content/gdrive/My Drive/shuffled_chest_xray2/test/NORMAL/00013310_003.jpeg\n",
            "NORMAL 600 / 1141  :  /content/gdrive/My Drive/shuffled_chest_xray2/test/NORMAL/00018142_000.jpeg\n",
            "NORMAL 800 / 1141  :  /content/gdrive/My Drive/shuffled_chest_xray2/test/NORMAL/00024667_000.jpeg\n",
            "NORMAL 1000 / 1141  :  /content/gdrive/My Drive/shuffled_chest_xray2/test/NORMAL/00000017_002.jpeg\n",
            "PNEUMONIA  파일 길이 :  1141\n",
            "PNEUMONIA 0 / 1141  :  /content/gdrive/My Drive/shuffled_chest_xray2/test/PNEUMONIA/00013992_029.jpeg\n",
            "PNEUMONIA 200 / 1141  :  /content/gdrive/My Drive/shuffled_chest_xray2/test/PNEUMONIA/person1093_bacteria_3033.jpeg\n",
            "PNEUMONIA 400 / 1141  :  /content/gdrive/My Drive/shuffled_chest_xray2/test/PNEUMONIA/person1460_bacteria_3801.jpeg\n",
            "PNEUMONIA 600 / 1141  :  /content/gdrive/My Drive/shuffled_chest_xray2/test/PNEUMONIA/person282_virus_579.jpeg\n",
            "PNEUMONIA 800 / 1141  :  /content/gdrive/My Drive/shuffled_chest_xray2/test/PNEUMONIA/person554_bacteria_2320.jpeg\n",
            "PNEUMONIA 1000 / 1141  :  /content/gdrive/My Drive/shuffled_chest_xray2/test/PNEUMONIA/00000398_002.jpeg\n",
            "change sets to list ok\n",
            "총 파일 수:  11417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48KFYhSl2KQy",
        "colab_type": "text"
      },
      "source": [
        "# 3. 필요한 모듈 임포트\n",
        "딥러닝 모델을 설계할 때 필요한 모듈들을 임포트 한다.<br>\n",
        "그리고 2번에서 전처리한 데이터를 불러온다.<br>\n",
        "데이터가 잘 섞여있나 확인을 위해 test set의 y값을 출력해본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ74_vx20Nsx",
        "colab_type": "code",
        "outputId": "c2ee83bf-2cb4-42a9-d7ba-03cfc13ca339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import os, glob, numpy as np\n",
        "import PIL\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation, BatchNormalization, ZeroPadding2D, InputLayer, GlobalAveragePooling2D\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend.tensorflow_backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.Session(config=config)\n",
        "\n",
        "X_train, y_train, X_test, y_test= np.load(\"/content/gdrive/My Drive/np/shuffled_data2.npy\", allow_pickle = True)\n",
        "print(\"is shuffled?: \")\n",
        "print(y_test[:20])\n",
        "print(\"training set shape: \" + str(X_train.shape))\n",
        "print(\"training set size: \" + str(X_train.shape[0]))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "is shuffled?: \n",
            "[[1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "training set shape: (9135, 224, 224, 3)\n",
            "training set size: 9135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8A6ZqJv2hnP",
        "colab_type": "text"
      },
      "source": [
        "# 4. RGB 값 일반화\n",
        "RGB 값은 0\\~255의 크기를 가지는데<br>\n",
        "학습하기 위해선 0~1의 크기이어야 한다.<br>\n",
        "따라서 크기를 바꿔준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G30J_zc0Paw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories = [\"NORMAL\", \"PNEUMONIA\"]\n",
        "nb_classes = len(categories)\n",
        "\n",
        "#일반화\n",
        "X_train = X_train.astype(float) / 255\n",
        "X_test = X_test.astype(float) / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY85W6GNoQxt",
        "colab_type": "text"
      },
      "source": [
        "# 5. 모델 설계\n",
        "다양한 모델을 설계하여 테스트 해본다.<br>\n",
        "전이 학습(transfer learning) 방식으로 VGG16, Inception V3, Resnet50을 사용하여 특징 추출을 하고, 평균풀링으로 분류기를 붙였다.<br>\n",
        "따라서 특징 추출부분은 가중치가 변하지 않고, 분류기 부분만 학습하도록 만들었다.<br>\n",
        "아래의 코드는 세 가지 전이 학습에서 사용할 모듈을 임포트하고,\n",
        "특징 추출시 사용할 함수이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSHcelwGl9B7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.applications import InceptionV3, VGG16, ResNet50\n",
        "\n",
        "def get_features(extractor, X, y):\n",
        "    extractor_shapes = list(extractor.get_output_shape_at(0)[1:])\n",
        "\n",
        "    features = extractor.predict(X)\n",
        "    labels = y\n",
        "    \n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4hHmvSSoQu6",
        "colab_type": "text"
      },
      "source": [
        "## 5.1.1 VGG16 전이 학습\n",
        "with 라인은 GPU를 사용하기 위한 코드다.<br>\n",
        "특징 추출기로 VGG16을 사용했다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRH_1r0grTcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with K.tf_ops.device('/device:GPU:0'):\n",
        "  extractor = Sequential()\n",
        "  extractor.add(VGG16(include_top=False, weights='imagenet', input_shape=X_train.shape[1:]))\n",
        "\n",
        "  extractor_output_shape = extractor.get_output_shape_at(0)[1:]\n",
        "\n",
        "  trainX, trainY = get_features(extractor, X_train, y_train)\n",
        "  testX, testY = get_features(extractor, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR5zZN2JrzYO",
        "colab_type": "text"
      },
      "source": [
        "아래의 코드는 분류기 코드로서, 특징 추출기와 연결되도록 만들어져 있다.\n",
        "validation loss값이 가장 낮은 것을 최종 모델의 형태로 하는데<br>\n",
        "학습 중 local optimum에 빠지는 것을 방지하기 위해<br>\n",
        "현재 가장 낮은 val_loss 값보다 큰 loss 값이 나와도 7번까지 더 학습을 수행한다.<br>\n",
        "7번까지 더 낮은 loss 값이 나오지 않으면 저장하고 있던 가장 낮은 loss 값으로 모델을 정의한다.<br>\n",
        "각각의 특징 추출기마다 출력 모양이 다른 것을 확인할 수 있다.\n",
        "\n",
        "전이 학습 종류마다 같은 코드가 들어간다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CcoLnuShrsM9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e0254a8c-cee2-4b24-f528-8358169df6cb"
      },
      "source": [
        "with K.tf_ops.device('/device:GPU:0'):\n",
        "  model = Sequential()\n",
        "  print(extractor_output_shape)\n",
        "  model.add(layers.InputLayer(input_shape=extractor_output_shape))\n",
        "  model.add(layers.GlobalAveragePooling2D()) # 2\n",
        "  model.add(layers.Dense(2, activation='sigmoid'))\n",
        "  \n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # 분류할 클래스가 3개 이상이면 categorical_crossentropy\n",
        "  model_dir = '/content/gdrive/My Drive/model'\n",
        "\n",
        "  if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)\n",
        "\n",
        "  model_path = model_dir + '/Xray_img_classification.model'\n",
        "  checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=7)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7, 7, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjSeh4JxoQUU",
        "colab_type": "text"
      },
      "source": [
        "## 5.1.2 VGG16 전이 학습 모델 형태\n",
        "위가 특징 추출기인 VGG16이고, 아래가 분류기다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvPJVT-3rT6c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "d9144d26-a4b3-4cc4-8949-1b39f2a1781d"
      },
      "source": [
        "extractor.summary()\n",
        "print(\"\\n\\n\")\n",
        "model.summary()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               12845568  \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 12,846,594\n",
            "Trainable params: 12,846,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NCflNi6pbP1",
        "colab_type": "text"
      },
      "source": [
        "## 5.2.1 Inception V3 전이 학습\n",
        "특징 추출기로 Inception V3를 사용했다.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzS_uPg6rUPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with K.tf_ops.device('/device:GPU:0'):\n",
        "  extractor = Sequential()\n",
        "  extractor.add(InceptionV3(include_top=False, weights='imagenet', input_shape=X_train.shape[1:]))\n",
        "\n",
        "  extractor_output_shape = extractor.get_output_shape_at(0)[1:]\n",
        "\n",
        "  trainX, trainY = get_features(extractor, X_train, y_train)\n",
        "  testX, testY = get_features(extractor, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QOkDzJOJrvyI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "df20bed5-fb70-4097-ff89-b45f9cff7b26"
      },
      "source": [
        "with K.tf_ops.device('/device:GPU:0'):\n",
        "  model = Sequential()\n",
        "  print(extractor_output_shape)\n",
        "  model.add(layers.InputLayer(input_shape=extractor_output_shape))\n",
        "  model.add(layers.GlobalAveragePooling2D()) # 2\n",
        "  model.add(layers.Dense(2, activation='sigmoid'))\n",
        "  \n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # 분류할 클래스가 3개 이상이면 categorical_crossentropy\n",
        "  model_dir = '/content/gdrive/My Drive/model'\n",
        "\n",
        "  if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)\n",
        "\n",
        "  model_path = model_dir + '/Xray_img_classification.model'\n",
        "  checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=7)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 5, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6yGnMNbsq5P",
        "colab_type": "text"
      },
      "source": [
        "## 5.2.2 Inception V3 전이 학습 모델 형태\n",
        "위가 특징 추출기인 Inception V3이고, 아래가 분류기다.<br>\n",
        "모델 형태는 5.1.2번의 모델의 형태에서 특징 추출기만 변한 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gxWHCYpsppE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "f2bf7fd0-d26b-4df7-8800-db7c1e747276"
      },
      "source": [
        "extractor.summary()\n",
        "print(\"\\n\\n\")\n",
        "model.summary()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_v3 (Model)         (None, 5, 5, 2048)        21802784  \n",
            "=================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_5 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 2048)              104859648 \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 2)                 4098      \n",
            "=================================================================\n",
            "Total params: 104,863,746\n",
            "Trainable params: 104,863,746\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olrvf0dcpbMc",
        "colab_type": "text"
      },
      "source": [
        "## 5.3 ResNet50 전이 학습\n",
        "특징 추출기로 ResNet50을 사용했다.<br>\n",
        "모델 형태는 5.1.2번의 모델의 형태에서 특징 추출기만 변한 것이다.\n",
        "아래의 코드는 특징 추출기를 정의한 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntfs0PotW_aF",
        "colab_type": "code",
        "outputId": "599b3c67-042d-4348-fd68-68d1a735e6ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "with K.tf_ops.device('/device:GPU:0'):\n",
        "  extractor = Sequential()\n",
        "  extractor.add(ResNet50(include_top=False, weights='imagenet', input_shape=X_train.shape[1:]))\n",
        "\n",
        "  extractor_output_shape = extractor.get_output_shape_at(0)[1:]\n",
        "\n",
        "  trainX, trainY = get_features(extractor, X_train, y_train)\n",
        "  testX, testY = get_features(extractor, X_test, y_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWg-SqqFJXg8",
        "colab_type": "code",
        "outputId": "a9738d82-c4d1-402b-f0b0-1519f818a9bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "with K.tf_ops.device('/device:GPU:0'):\n",
        "  model = Sequential()\n",
        "  print(extractor_output_shape)\n",
        "  model.add(layers.InputLayer(input_shape=extractor_output_shape))\n",
        "  model.add(layers.GlobalAveragePooling2D()) # 2\n",
        "  model.add(layers.Dense(2, activation='sigmoid'))\n",
        "  \n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # 분류할 클래스가 3개 이상이면 categorical_crossentropy\n",
        "  model_dir = '/content/gdrive/My Drive/model'\n",
        "\n",
        "  if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)\n",
        "\n",
        "  model_path = model_dir + '/Xray_img_classification.model'\n",
        "  checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=7)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7, 7, 2048)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6kjbihRs-OO",
        "colab_type": "text"
      },
      "source": [
        "## 5.3.2 ResNet50 전이 학습 모델 형태\n",
        "위가 특징 추출기인 ResNet50이고, 아래가 분류기다.<br>\n",
        "모델 형태는 5.1.2번의 모델의 형태에서 특징 추출기만 변한 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3GUi4c8s-AW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "b022dc61-ec70-4199-d647-4e9c0c75079f"
      },
      "source": [
        "extractor.summary()\n",
        "print(\"\\n\\n\")\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
            "=================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 4098      \n",
            "=================================================================\n",
            "Total params: 4,098\n",
            "Trainable params: 4,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAEEvy0Y7Jo6",
        "colab_type": "text"
      },
      "source": [
        "# 6. 학습 및 학습과정 저장\n",
        "모델을 학습시키고 학습과정을 그래프로 나타내기 위해 학습과정을 저장한다.<br>\n",
        "학습 중에 training set의 일부(20%)를 validation set으로 이용하여 평가한다.<br>\n",
        "(밑의 실행한 fit은 ResNet50을 사용한 전이 학습 코드다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fh1yViK0WVW",
        "colab_type": "code",
        "outputId": "e9ef7ee1-41b4-4f50-87be-b82aaa53aab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(trainX, trainY, batch_size=64, epochs=1000, validation_split=0.2, shuffle=True, callbacks=[checkpoint, early_stopping])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7308 samples, validate on 1827 samples\n",
            "Epoch 1/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.6927 - acc: 0.5304\n",
            "Epoch 00001: val_loss improved from inf to 0.68216, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 26s 4ms/sample - loss: 0.6928 - acc: 0.5295 - val_loss: 0.6822 - val_acc: 0.5520\n",
            "Epoch 2/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.6762 - acc: 0.6006\n",
            "Epoch 00002: val_loss improved from 0.68216 to 0.67894, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 320us/sample - loss: 0.6768 - acc: 0.5975 - val_loss: 0.6789 - val_acc: 0.5172\n",
            "Epoch 3/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.6683 - acc: 0.6356\n",
            "Epoch 00003: val_loss improved from 0.67894 to 0.66514, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 312us/sample - loss: 0.6681 - acc: 0.6359 - val_loss: 0.6651 - val_acc: 0.6013\n",
            "Epoch 4/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.6548 - acc: 0.6820\n",
            "Epoch 00004: val_loss improved from 0.66514 to 0.65768, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 323us/sample - loss: 0.6549 - acc: 0.6819 - val_loss: 0.6577 - val_acc: 0.6092\n",
            "Epoch 5/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.6439 - acc: 0.6895\n",
            "Epoch 00005: val_loss improved from 0.65768 to 0.64347, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 314us/sample - loss: 0.6436 - acc: 0.6910 - val_loss: 0.6435 - val_acc: 0.7384\n",
            "Epoch 6/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.6353 - acc: 0.7370\n",
            "Epoch 00006: val_loss improved from 0.64347 to 0.64042, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.6350 - acc: 0.7369 - val_loss: 0.6404 - val_acc: 0.6308\n",
            "Epoch 7/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.6292 - acc: 0.7101\n",
            "Epoch 00007: val_loss improved from 0.64042 to 0.62715, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 317us/sample - loss: 0.6292 - acc: 0.7098 - val_loss: 0.6272 - val_acc: 0.7537\n",
            "Epoch 8/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.6193 - acc: 0.7408\n",
            "Epoch 00008: val_loss improved from 0.62715 to 0.62062, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 310us/sample - loss: 0.6193 - acc: 0.7413 - val_loss: 0.6206 - val_acc: 0.7474\n",
            "Epoch 9/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.6113 - acc: 0.7450\n",
            "Epoch 00009: val_loss improved from 0.62062 to 0.61370, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.6114 - acc: 0.7449 - val_loss: 0.6137 - val_acc: 0.7438\n",
            "Epoch 10/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.6040 - acc: 0.7577\n",
            "Epoch 00010: val_loss improved from 0.61370 to 0.61056, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.6042 - acc: 0.7575 - val_loss: 0.6106 - val_acc: 0.7307\n",
            "Epoch 11/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.5968 - acc: 0.7752\n",
            "Epoch 00011: val_loss improved from 0.61056 to 0.59964, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 316us/sample - loss: 0.5965 - acc: 0.7759 - val_loss: 0.5996 - val_acc: 0.7718\n",
            "Epoch 12/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.5923 - acc: 0.7584\n",
            "Epoch 00012: val_loss did not improve from 0.59964\n",
            "7308/7308 [==============================] - 2s 312us/sample - loss: 0.5922 - acc: 0.7573 - val_loss: 0.6006 - val_acc: 0.7069\n",
            "Epoch 13/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.5835 - acc: 0.7852\n",
            "Epoch 00013: val_loss improved from 0.59964 to 0.58778, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 310us/sample - loss: 0.5838 - acc: 0.7846 - val_loss: 0.5878 - val_acc: 0.7745\n",
            "Epoch 14/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.5779 - acc: 0.7820\n",
            "Epoch 00014: val_loss improved from 0.58778 to 0.58369, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.5778 - acc: 0.7821 - val_loss: 0.5837 - val_acc: 0.7731\n",
            "Epoch 15/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.5727 - acc: 0.7938\n",
            "Epoch 00015: val_loss improved from 0.58369 to 0.57772, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.5726 - acc: 0.7941 - val_loss: 0.5777 - val_acc: 0.7824\n",
            "Epoch 16/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.5665 - acc: 0.7952\n",
            "Epoch 00016: val_loss improved from 0.57772 to 0.57404, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.5665 - acc: 0.7953 - val_loss: 0.5740 - val_acc: 0.7775\n",
            "Epoch 17/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.5618 - acc: 0.8035\n",
            "Epoch 00017: val_loss improved from 0.57404 to 0.56927, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 329us/sample - loss: 0.5618 - acc: 0.8032 - val_loss: 0.5693 - val_acc: 0.7802\n",
            "Epoch 18/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.5569 - acc: 0.7957\n",
            "Epoch 00018: val_loss did not improve from 0.56927\n",
            "7308/7308 [==============================] - 2s 304us/sample - loss: 0.5568 - acc: 0.7959 - val_loss: 0.5693 - val_acc: 0.7534\n",
            "Epoch 19/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.5523 - acc: 0.8049\n",
            "Epoch 00019: val_loss improved from 0.56927 to 0.55807, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.5521 - acc: 0.8052 - val_loss: 0.5581 - val_acc: 0.7893\n",
            "Epoch 20/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.5470 - acc: 0.8081\n",
            "Epoch 00020: val_loss improved from 0.55807 to 0.55354, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.5472 - acc: 0.8082 - val_loss: 0.5535 - val_acc: 0.7939\n",
            "Epoch 21/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.5448 - acc: 0.8043\n",
            "Epoch 00021: val_loss improved from 0.55354 to 0.54918, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.5442 - acc: 0.8048 - val_loss: 0.5492 - val_acc: 0.7961\n",
            "Epoch 22/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.5396 - acc: 0.8126\n",
            "Epoch 00022: val_loss improved from 0.54918 to 0.54838, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.5391 - acc: 0.8126 - val_loss: 0.5484 - val_acc: 0.7912\n",
            "Epoch 23/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.5344 - acc: 0.8151\n",
            "Epoch 00023: val_loss improved from 0.54838 to 0.54103, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 326us/sample - loss: 0.5347 - acc: 0.8142 - val_loss: 0.5410 - val_acc: 0.7991\n",
            "Epoch 24/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.5310 - acc: 0.8175\n",
            "Epoch 00024: val_loss improved from 0.54103 to 0.53912, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 316us/sample - loss: 0.5304 - acc: 0.8178 - val_loss: 0.5391 - val_acc: 0.7882\n",
            "Epoch 25/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.5268 - acc: 0.8171\n",
            "Epoch 00025: val_loss improved from 0.53912 to 0.53706, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.5266 - acc: 0.8175 - val_loss: 0.5371 - val_acc: 0.7997\n",
            "Epoch 26/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.5235 - acc: 0.8159\n",
            "Epoch 00026: val_loss improved from 0.53706 to 0.53181, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.5238 - acc: 0.8157 - val_loss: 0.5318 - val_acc: 0.8027\n",
            "Epoch 27/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.5211 - acc: 0.8124\n",
            "Epoch 00027: val_loss improved from 0.53181 to 0.52842, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.5210 - acc: 0.8126 - val_loss: 0.5284 - val_acc: 0.8024\n",
            "Epoch 28/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.5182 - acc: 0.8153\n",
            "Epoch 00028: val_loss did not improve from 0.52842\n",
            "7308/7308 [==============================] - 2s 319us/sample - loss: 0.5179 - acc: 0.8153 - val_loss: 0.5353 - val_acc: 0.7701\n",
            "Epoch 29/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.5163 - acc: 0.8134\n",
            "Epoch 00029: val_loss did not improve from 0.52842\n",
            "7308/7308 [==============================] - 2s 321us/sample - loss: 0.5163 - acc: 0.8133 - val_loss: 0.5374 - val_acc: 0.7805\n",
            "Epoch 30/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.5107 - acc: 0.8251\n",
            "Epoch 00030: val_loss improved from 0.52842 to 0.51798, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.5106 - acc: 0.8251 - val_loss: 0.5180 - val_acc: 0.8068\n",
            "Epoch 31/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.5080 - acc: 0.8259\n",
            "Epoch 00031: val_loss improved from 0.51798 to 0.51607, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.5077 - acc: 0.8252 - val_loss: 0.5161 - val_acc: 0.8041\n",
            "Epoch 32/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.5052 - acc: 0.8233\n",
            "Epoch 00032: val_loss improved from 0.51607 to 0.51253, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.5050 - acc: 0.8236 - val_loss: 0.5125 - val_acc: 0.8128\n",
            "Epoch 33/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.5025 - acc: 0.8242\n",
            "Epoch 00033: val_loss improved from 0.51253 to 0.51187, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.5024 - acc: 0.8242 - val_loss: 0.5119 - val_acc: 0.8093\n",
            "Epoch 34/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4988 - acc: 0.8273\n",
            "Epoch 00034: val_loss improved from 0.51187 to 0.50728, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 312us/sample - loss: 0.4989 - acc: 0.8277 - val_loss: 0.5073 - val_acc: 0.8065\n",
            "Epoch 35/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4984 - acc: 0.8224\n",
            "Epoch 00035: val_loss did not improve from 0.50728\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4983 - acc: 0.8235 - val_loss: 0.5091 - val_acc: 0.8076\n",
            "Epoch 36/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4957 - acc: 0.8221\n",
            "Epoch 00036: val_loss did not improve from 0.50728\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.4948 - acc: 0.8229 - val_loss: 0.5109 - val_acc: 0.8024\n",
            "Epoch 37/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4936 - acc: 0.8286\n",
            "Epoch 00037: val_loss improved from 0.50728 to 0.50252, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 323us/sample - loss: 0.4932 - acc: 0.8290 - val_loss: 0.5025 - val_acc: 0.8114\n",
            "Epoch 38/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4888 - acc: 0.8285\n",
            "Epoch 00038: val_loss improved from 0.50252 to 0.49804, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 339us/sample - loss: 0.4886 - acc: 0.8287 - val_loss: 0.4980 - val_acc: 0.8150\n",
            "Epoch 39/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4868 - acc: 0.8311\n",
            "Epoch 00039: val_loss did not improve from 0.49804\n",
            "7308/7308 [==============================] - 2s 314us/sample - loss: 0.4867 - acc: 0.8308 - val_loss: 0.4991 - val_acc: 0.8019\n",
            "Epoch 40/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4846 - acc: 0.8282\n",
            "Epoch 00040: val_loss improved from 0.49804 to 0.49521, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.4850 - acc: 0.8277 - val_loss: 0.4952 - val_acc: 0.8150\n",
            "Epoch 41/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4851 - acc: 0.8240\n",
            "Epoch 00041: val_loss improved from 0.49521 to 0.49212, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 310us/sample - loss: 0.4844 - acc: 0.8246 - val_loss: 0.4921 - val_acc: 0.8139\n",
            "Epoch 42/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4817 - acc: 0.8258\n",
            "Epoch 00042: val_loss improved from 0.49212 to 0.48964, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4814 - acc: 0.8261 - val_loss: 0.4896 - val_acc: 0.8175\n",
            "Epoch 43/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4787 - acc: 0.8270\n",
            "Epoch 00043: val_loss improved from 0.48964 to 0.48760, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4787 - acc: 0.8272 - val_loss: 0.4876 - val_acc: 0.8166\n",
            "Epoch 44/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4790 - acc: 0.8276\n",
            "Epoch 00044: val_loss improved from 0.48760 to 0.48572, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 310us/sample - loss: 0.4789 - acc: 0.8278 - val_loss: 0.4857 - val_acc: 0.8161\n",
            "Epoch 45/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4760 - acc: 0.8287\n",
            "Epoch 00045: val_loss improved from 0.48572 to 0.48557, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.4760 - acc: 0.8289 - val_loss: 0.4856 - val_acc: 0.8196\n",
            "Epoch 46/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4743 - acc: 0.8290\n",
            "Epoch 00046: val_loss did not improve from 0.48557\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4725 - acc: 0.8308 - val_loss: 0.4896 - val_acc: 0.8128\n",
            "Epoch 47/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4726 - acc: 0.8265\n",
            "Epoch 00047: val_loss did not improve from 0.48557\n",
            "7308/7308 [==============================] - 2s 299us/sample - loss: 0.4723 - acc: 0.8270 - val_loss: 0.4864 - val_acc: 0.8144\n",
            "Epoch 48/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4705 - acc: 0.8293\n",
            "Epoch 00048: val_loss improved from 0.48557 to 0.47944, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 310us/sample - loss: 0.4705 - acc: 0.8287 - val_loss: 0.4794 - val_acc: 0.8180\n",
            "Epoch 49/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.8304\n",
            "Epoch 00049: val_loss did not improve from 0.47944\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4675 - acc: 0.8305 - val_loss: 0.4809 - val_acc: 0.8186\n",
            "Epoch 50/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4681 - acc: 0.8285\n",
            "Epoch 00050: val_loss improved from 0.47944 to 0.47673, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 316us/sample - loss: 0.4680 - acc: 0.8285 - val_loss: 0.4767 - val_acc: 0.8207\n",
            "Epoch 51/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4650 - acc: 0.8276\n",
            "Epoch 00051: val_loss improved from 0.47673 to 0.47474, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 318us/sample - loss: 0.4647 - acc: 0.8282 - val_loss: 0.4747 - val_acc: 0.8177\n",
            "Epoch 52/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4642 - acc: 0.8313\n",
            "Epoch 00052: val_loss improved from 0.47474 to 0.47317, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 325us/sample - loss: 0.4640 - acc: 0.8313 - val_loss: 0.4732 - val_acc: 0.8224\n",
            "Epoch 53/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.8316\n",
            "Epoch 00053: val_loss did not improve from 0.47317\n",
            "7308/7308 [==============================] - 2s 315us/sample - loss: 0.4617 - acc: 0.8313 - val_loss: 0.4782 - val_acc: 0.8158\n",
            "Epoch 54/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4615 - acc: 0.8307\n",
            "Epoch 00054: val_loss improved from 0.47317 to 0.47308, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 315us/sample - loss: 0.4617 - acc: 0.8303 - val_loss: 0.4731 - val_acc: 0.8224\n",
            "Epoch 55/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4594 - acc: 0.8315\n",
            "Epoch 00055: val_loss did not improve from 0.47308\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.4600 - acc: 0.8309 - val_loss: 0.4900 - val_acc: 0.8062\n",
            "Epoch 56/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4619 - acc: 0.8296\n",
            "Epoch 00056: val_loss improved from 0.47308 to 0.46797, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 317us/sample - loss: 0.4611 - acc: 0.8300 - val_loss: 0.4680 - val_acc: 0.8246\n",
            "Epoch 57/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4584 - acc: 0.8327\n",
            "Epoch 00057: val_loss did not improve from 0.46797\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.4587 - acc: 0.8326 - val_loss: 0.4733 - val_acc: 0.8166\n",
            "Epoch 58/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4547 - acc: 0.8334\n",
            "Epoch 00058: val_loss improved from 0.46797 to 0.46591, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 313us/sample - loss: 0.4548 - acc: 0.8334 - val_loss: 0.4659 - val_acc: 0.8216\n",
            "Epoch 59/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4538 - acc: 0.8320\n",
            "Epoch 00059: val_loss improved from 0.46591 to 0.46436, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 313us/sample - loss: 0.4532 - acc: 0.8325 - val_loss: 0.4644 - val_acc: 0.8240\n",
            "Epoch 60/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4533 - acc: 0.8333\n",
            "Epoch 00060: val_loss did not improve from 0.46436\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.4539 - acc: 0.8334 - val_loss: 0.4662 - val_acc: 0.8227\n",
            "Epoch 61/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4495 - acc: 0.8348\n",
            "Epoch 00061: val_loss improved from 0.46436 to 0.46371, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 312us/sample - loss: 0.4509 - acc: 0.8332 - val_loss: 0.4637 - val_acc: 0.8238\n",
            "Epoch 62/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4515 - acc: 0.8313\n",
            "Epoch 00062: val_loss did not improve from 0.46371\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4515 - acc: 0.8311 - val_loss: 0.4659 - val_acc: 0.8218\n",
            "Epoch 63/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4495 - acc: 0.8342\n",
            "Epoch 00063: val_loss improved from 0.46371 to 0.46224, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 311us/sample - loss: 0.4497 - acc: 0.8339 - val_loss: 0.4622 - val_acc: 0.8235\n",
            "Epoch 64/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4495 - acc: 0.8306\n",
            "Epoch 00064: val_loss improved from 0.46224 to 0.46011, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4501 - acc: 0.8299 - val_loss: 0.4601 - val_acc: 0.8235\n",
            "Epoch 65/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.8333\n",
            "Epoch 00065: val_loss improved from 0.46011 to 0.45829, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 310us/sample - loss: 0.4464 - acc: 0.8336 - val_loss: 0.4583 - val_acc: 0.8248\n",
            "Epoch 66/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4460 - acc: 0.8330\n",
            "Epoch 00066: val_loss did not improve from 0.45829\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4454 - acc: 0.8335 - val_loss: 0.4587 - val_acc: 0.8235\n",
            "Epoch 67/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4452 - acc: 0.8328\n",
            "Epoch 00067: val_loss did not improve from 0.45829\n",
            "7308/7308 [==============================] - 2s 310us/sample - loss: 0.4452 - acc: 0.8326 - val_loss: 0.4611 - val_acc: 0.8240\n",
            "Epoch 68/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4453 - acc: 0.8316\n",
            "Epoch 00068: val_loss improved from 0.45829 to 0.45569, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 312us/sample - loss: 0.4447 - acc: 0.8323 - val_loss: 0.4557 - val_acc: 0.8238\n",
            "Epoch 69/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4461 - acc: 0.8329\n",
            "Epoch 00069: val_loss improved from 0.45569 to 0.45453, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 310us/sample - loss: 0.4451 - acc: 0.8336 - val_loss: 0.4545 - val_acc: 0.8276\n",
            "Epoch 70/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4436 - acc: 0.8315\n",
            "Epoch 00070: val_loss did not improve from 0.45453\n",
            "7308/7308 [==============================] - 2s 302us/sample - loss: 0.4427 - acc: 0.8324 - val_loss: 0.4665 - val_acc: 0.8183\n",
            "Epoch 71/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4428 - acc: 0.8313\n",
            "Epoch 00071: val_loss did not improve from 0.45453\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.4431 - acc: 0.8309 - val_loss: 0.4565 - val_acc: 0.8243\n",
            "Epoch 72/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4415 - acc: 0.8325\n",
            "Epoch 00072: val_loss improved from 0.45453 to 0.45207, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 312us/sample - loss: 0.4411 - acc: 0.8331 - val_loss: 0.4521 - val_acc: 0.8281\n",
            "Epoch 73/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4418 - acc: 0.8345\n",
            "Epoch 00073: val_loss improved from 0.45207 to 0.45172, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 310us/sample - loss: 0.4417 - acc: 0.8345 - val_loss: 0.4517 - val_acc: 0.8235\n",
            "Epoch 74/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4403 - acc: 0.8366\n",
            "Epoch 00074: val_loss did not improve from 0.45172\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.4406 - acc: 0.8363 - val_loss: 0.4531 - val_acc: 0.8229\n",
            "Epoch 75/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4388 - acc: 0.8354\n",
            "Epoch 00075: val_loss improved from 0.45172 to 0.45010, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.4379 - acc: 0.8362 - val_loss: 0.4501 - val_acc: 0.8246\n",
            "Epoch 76/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4360 - acc: 0.8336\n",
            "Epoch 00076: val_loss improved from 0.45010 to 0.44894, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 304us/sample - loss: 0.4369 - acc: 0.8329 - val_loss: 0.4489 - val_acc: 0.8284\n",
            "Epoch 77/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4365 - acc: 0.8330\n",
            "Epoch 00077: val_loss did not improve from 0.44894\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4371 - acc: 0.8321 - val_loss: 0.4627 - val_acc: 0.8183\n",
            "Epoch 78/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4360 - acc: 0.8369\n",
            "Epoch 00078: val_loss improved from 0.44894 to 0.44837, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4361 - acc: 0.8361 - val_loss: 0.4484 - val_acc: 0.8235\n",
            "Epoch 79/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4348 - acc: 0.8346\n",
            "Epoch 00079: val_loss did not improve from 0.44837\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.4351 - acc: 0.8346 - val_loss: 0.4640 - val_acc: 0.8172\n",
            "Epoch 80/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4358 - acc: 0.8371\n",
            "Epoch 00080: val_loss did not improve from 0.44837\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4364 - acc: 0.8357 - val_loss: 0.4488 - val_acc: 0.8240\n",
            "Epoch 81/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4343 - acc: 0.8351\n",
            "Epoch 00081: val_loss improved from 0.44837 to 0.44546, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 319us/sample - loss: 0.4341 - acc: 0.8352 - val_loss: 0.4455 - val_acc: 0.8276\n",
            "Epoch 82/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4327 - acc: 0.8345\n",
            "Epoch 00082: val_loss improved from 0.44546 to 0.44493, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 310us/sample - loss: 0.4321 - acc: 0.8356 - val_loss: 0.4449 - val_acc: 0.8257\n",
            "Epoch 83/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4323 - acc: 0.8338\n",
            "Epoch 00083: val_loss did not improve from 0.44493\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4319 - acc: 0.8341 - val_loss: 0.4461 - val_acc: 0.8232\n",
            "Epoch 84/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4320 - acc: 0.8371\n",
            "Epoch 00084: val_loss improved from 0.44493 to 0.44472, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 304us/sample - loss: 0.4322 - acc: 0.8366 - val_loss: 0.4447 - val_acc: 0.8218\n",
            "Epoch 85/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4304 - acc: 0.8354\n",
            "Epoch 00085: val_loss did not improve from 0.44472\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4306 - acc: 0.8350 - val_loss: 0.4463 - val_acc: 0.8240\n",
            "Epoch 86/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4303 - acc: 0.8361\n",
            "Epoch 00086: val_loss did not improve from 0.44472\n",
            "7308/7308 [==============================] - 2s 310us/sample - loss: 0.4308 - acc: 0.8362 - val_loss: 0.4453 - val_acc: 0.8221\n",
            "Epoch 87/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4297 - acc: 0.8354\n",
            "Epoch 00087: val_loss improved from 0.44472 to 0.44375, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 3s 346us/sample - loss: 0.4297 - acc: 0.8354 - val_loss: 0.4438 - val_acc: 0.8199\n",
            "Epoch 88/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4305 - acc: 0.8367\n",
            "Epoch 00088: val_loss did not improve from 0.44375\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.4295 - acc: 0.8366 - val_loss: 0.4445 - val_acc: 0.8216\n",
            "Epoch 89/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4286 - acc: 0.8361\n",
            "Epoch 00089: val_loss did not improve from 0.44375\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4289 - acc: 0.8359 - val_loss: 0.4447 - val_acc: 0.8251\n",
            "Epoch 90/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4268 - acc: 0.8379\n",
            "Epoch 00090: val_loss did not improve from 0.44375\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.4275 - acc: 0.8377 - val_loss: 0.4459 - val_acc: 0.8144\n",
            "Epoch 91/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4285 - acc: 0.8337\n",
            "Epoch 00091: val_loss improved from 0.44375 to 0.44241, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 3s 361us/sample - loss: 0.4282 - acc: 0.8339 - val_loss: 0.4424 - val_acc: 0.8254\n",
            "Epoch 92/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4259 - acc: 0.8366\n",
            "Epoch 00092: val_loss improved from 0.44241 to 0.44065, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4258 - acc: 0.8365 - val_loss: 0.4406 - val_acc: 0.8248\n",
            "Epoch 93/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4263 - acc: 0.8381\n",
            "Epoch 00093: val_loss improved from 0.44065 to 0.43889, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 312us/sample - loss: 0.4260 - acc: 0.8378 - val_loss: 0.4389 - val_acc: 0.8287\n",
            "Epoch 94/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4258 - acc: 0.8390\n",
            "Epoch 00094: val_loss did not improve from 0.43889\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.4255 - acc: 0.8391 - val_loss: 0.4527 - val_acc: 0.8227\n",
            "Epoch 95/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4261 - acc: 0.8357\n",
            "Epoch 00095: val_loss did not improve from 0.43889\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.4264 - acc: 0.8351 - val_loss: 0.4398 - val_acc: 0.8218\n",
            "Epoch 96/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4247 - acc: 0.8356\n",
            "Epoch 00096: val_loss did not improve from 0.43889\n",
            "7308/7308 [==============================] - 2s 304us/sample - loss: 0.4244 - acc: 0.8359 - val_loss: 0.4414 - val_acc: 0.8262\n",
            "Epoch 97/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4236 - acc: 0.8373\n",
            "Epoch 00097: val_loss improved from 0.43889 to 0.43659, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 336us/sample - loss: 0.4239 - acc: 0.8368 - val_loss: 0.4366 - val_acc: 0.8268\n",
            "Epoch 98/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4225 - acc: 0.8359\n",
            "Epoch 00098: val_loss did not improve from 0.43659\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.4226 - acc: 0.8359 - val_loss: 0.4371 - val_acc: 0.8265\n",
            "Epoch 99/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4221 - acc: 0.8371\n",
            "Epoch 00099: val_loss improved from 0.43659 to 0.43612, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 312us/sample - loss: 0.4212 - acc: 0.8375 - val_loss: 0.4361 - val_acc: 0.8284\n",
            "Epoch 100/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4207 - acc: 0.8376\n",
            "Epoch 00100: val_loss did not improve from 0.43612\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.4216 - acc: 0.8370 - val_loss: 0.4410 - val_acc: 0.8166\n",
            "Epoch 101/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4209 - acc: 0.8350\n",
            "Epoch 00101: val_loss did not improve from 0.43612\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4218 - acc: 0.8345 - val_loss: 0.4366 - val_acc: 0.8281\n",
            "Epoch 102/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4196 - acc: 0.8391\n",
            "Epoch 00102: val_loss improved from 0.43612 to 0.43414, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 339us/sample - loss: 0.4205 - acc: 0.8386 - val_loss: 0.4341 - val_acc: 0.8295\n",
            "Epoch 103/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4222 - acc: 0.8325\n",
            "Epoch 00103: val_loss did not improve from 0.43414\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.4209 - acc: 0.8332 - val_loss: 0.4347 - val_acc: 0.8273\n",
            "Epoch 104/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4189 - acc: 0.8366\n",
            "Epoch 00104: val_loss did not improve from 0.43414\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.4189 - acc: 0.8366 - val_loss: 0.4409 - val_acc: 0.8169\n",
            "Epoch 105/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4194 - acc: 0.8385\n",
            "Epoch 00105: val_loss did not improve from 0.43414\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.4219 - acc: 0.8369 - val_loss: 0.4394 - val_acc: 0.8268\n",
            "Epoch 106/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4185 - acc: 0.8388\n",
            "Epoch 00106: val_loss improved from 0.43414 to 0.43325, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 341us/sample - loss: 0.4185 - acc: 0.8387 - val_loss: 0.4332 - val_acc: 0.8246\n",
            "Epoch 107/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4189 - acc: 0.8363\n",
            "Epoch 00107: val_loss improved from 0.43325 to 0.43244, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4196 - acc: 0.8355 - val_loss: 0.4324 - val_acc: 0.8265\n",
            "Epoch 108/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4181 - acc: 0.8367\n",
            "Epoch 00108: val_loss improved from 0.43244 to 0.43165, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 311us/sample - loss: 0.4181 - acc: 0.8367 - val_loss: 0.4316 - val_acc: 0.8290\n",
            "Epoch 109/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4174 - acc: 0.8389\n",
            "Epoch 00109: val_loss did not improve from 0.43165\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.4179 - acc: 0.8385 - val_loss: 0.4321 - val_acc: 0.8287\n",
            "Epoch 110/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4174 - acc: 0.8384\n",
            "Epoch 00110: val_loss did not improve from 0.43165\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.4168 - acc: 0.8390 - val_loss: 0.4496 - val_acc: 0.8238\n",
            "Epoch 111/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4172 - acc: 0.8376\n",
            "Epoch 00111: val_loss did not improve from 0.43165\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.4161 - acc: 0.8382 - val_loss: 0.4365 - val_acc: 0.8273\n",
            "Epoch 112/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4158 - acc: 0.8366\n",
            "Epoch 00112: val_loss improved from 0.43165 to 0.43016, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 3s 344us/sample - loss: 0.4159 - acc: 0.8363 - val_loss: 0.4302 - val_acc: 0.8295\n",
            "Epoch 113/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4206 - acc: 0.8368\n",
            "Epoch 00113: val_loss did not improve from 0.43016\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.4207 - acc: 0.8368 - val_loss: 0.4315 - val_acc: 0.8276\n",
            "Epoch 114/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4151 - acc: 0.8382\n",
            "Epoch 00114: val_loss improved from 0.43016 to 0.42961, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.4149 - acc: 0.8383 - val_loss: 0.4296 - val_acc: 0.8287\n",
            "Epoch 115/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4137 - acc: 0.8359\n",
            "Epoch 00115: val_loss did not improve from 0.42961\n",
            "7308/7308 [==============================] - 2s 310us/sample - loss: 0.4147 - acc: 0.8361 - val_loss: 0.4304 - val_acc: 0.8295\n",
            "Epoch 116/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4147 - acc: 0.8398\n",
            "Epoch 00116: val_loss improved from 0.42961 to 0.42917, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 311us/sample - loss: 0.4149 - acc: 0.8395 - val_loss: 0.4292 - val_acc: 0.8290\n",
            "Epoch 117/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4147 - acc: 0.8387\n",
            "Epoch 00117: val_loss did not improve from 0.42917\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4136 - acc: 0.8396 - val_loss: 0.4332 - val_acc: 0.8273\n",
            "Epoch 118/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4137 - acc: 0.8368\n",
            "Epoch 00118: val_loss improved from 0.42917 to 0.42815, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 311us/sample - loss: 0.4140 - acc: 0.8366 - val_loss: 0.4282 - val_acc: 0.8298\n",
            "Epoch 119/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4125 - acc: 0.8364\n",
            "Epoch 00119: val_loss did not improve from 0.42815\n",
            "7308/7308 [==============================] - 2s 311us/sample - loss: 0.4129 - acc: 0.8361 - val_loss: 0.4312 - val_acc: 0.8221\n",
            "Epoch 120/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4146 - acc: 0.8384\n",
            "Epoch 00120: val_loss improved from 0.42815 to 0.42741, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 311us/sample - loss: 0.4140 - acc: 0.8385 - val_loss: 0.4274 - val_acc: 0.8303\n",
            "Epoch 121/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4125 - acc: 0.8394\n",
            "Epoch 00121: val_loss did not improve from 0.42741\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.4120 - acc: 0.8396 - val_loss: 0.4285 - val_acc: 0.8300\n",
            "Epoch 122/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4121 - acc: 0.8388\n",
            "Epoch 00122: val_loss improved from 0.42741 to 0.42723, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 311us/sample - loss: 0.4120 - acc: 0.8389 - val_loss: 0.4272 - val_acc: 0.8273\n",
            "Epoch 123/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4119 - acc: 0.8393\n",
            "Epoch 00123: val_loss did not improve from 0.42723\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4118 - acc: 0.8394 - val_loss: 0.4273 - val_acc: 0.8303\n",
            "Epoch 124/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4110 - acc: 0.8395\n",
            "Epoch 00124: val_loss did not improve from 0.42723\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.4115 - acc: 0.8394 - val_loss: 0.4291 - val_acc: 0.8235\n",
            "Epoch 125/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4117 - acc: 0.8376\n",
            "Epoch 00125: val_loss did not improve from 0.42723\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4124 - acc: 0.8378 - val_loss: 0.4279 - val_acc: 0.8284\n",
            "Epoch 126/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4110 - acc: 0.8394\n",
            "Epoch 00126: val_loss did not improve from 0.42723\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.4116 - acc: 0.8396 - val_loss: 0.4317 - val_acc: 0.8279\n",
            "Epoch 127/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4105 - acc: 0.8386\n",
            "Epoch 00127: val_loss improved from 0.42723 to 0.42629, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 3s 348us/sample - loss: 0.4105 - acc: 0.8387 - val_loss: 0.4263 - val_acc: 0.8311\n",
            "Epoch 128/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4096 - acc: 0.8379\n",
            "Epoch 00128: val_loss did not improve from 0.42629\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4088 - acc: 0.8387 - val_loss: 0.4263 - val_acc: 0.8325\n",
            "Epoch 129/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4089 - acc: 0.8394\n",
            "Epoch 00129: val_loss did not improve from 0.42629\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4099 - acc: 0.8389 - val_loss: 0.4295 - val_acc: 0.8270\n",
            "Epoch 130/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4103 - acc: 0.8409\n",
            "Epoch 00130: val_loss improved from 0.42629 to 0.42444, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 337us/sample - loss: 0.4101 - acc: 0.8411 - val_loss: 0.4244 - val_acc: 0.8300\n",
            "Epoch 131/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4107 - acc: 0.8386\n",
            "Epoch 00131: val_loss did not improve from 0.42444\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4100 - acc: 0.8386 - val_loss: 0.4249 - val_acc: 0.8311\n",
            "Epoch 132/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4089 - acc: 0.8407\n",
            "Epoch 00132: val_loss improved from 0.42444 to 0.42414, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4089 - acc: 0.8409 - val_loss: 0.4241 - val_acc: 0.8290\n",
            "Epoch 133/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4098 - acc: 0.8385\n",
            "Epoch 00133: val_loss improved from 0.42414 to 0.42375, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 311us/sample - loss: 0.4088 - acc: 0.8388 - val_loss: 0.4237 - val_acc: 0.8314\n",
            "Epoch 134/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4074 - acc: 0.8425\n",
            "Epoch 00134: val_loss improved from 0.42375 to 0.42335, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.4081 - acc: 0.8418 - val_loss: 0.4233 - val_acc: 0.8306\n",
            "Epoch 135/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4076 - acc: 0.8406\n",
            "Epoch 00135: val_loss did not improve from 0.42335\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4074 - acc: 0.8405 - val_loss: 0.4247 - val_acc: 0.8306\n",
            "Epoch 136/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4097 - acc: 0.8376\n",
            "Epoch 00136: val_loss did not improve from 0.42335\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4099 - acc: 0.8374 - val_loss: 0.4239 - val_acc: 0.8328\n",
            "Epoch 137/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4068 - acc: 0.8394\n",
            "Epoch 00137: val_loss did not improve from 0.42335\n",
            "7308/7308 [==============================] - 2s 310us/sample - loss: 0.4080 - acc: 0.8391 - val_loss: 0.4333 - val_acc: 0.8290\n",
            "Epoch 138/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4053 - acc: 0.8416\n",
            "Epoch 00138: val_loss did not improve from 0.42335\n",
            "7308/7308 [==============================] - 2s 315us/sample - loss: 0.4067 - acc: 0.8412 - val_loss: 0.4251 - val_acc: 0.8284\n",
            "Epoch 139/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4064 - acc: 0.8399\n",
            "Epoch 00139: val_loss did not improve from 0.42335\n",
            "7308/7308 [==============================] - 2s 312us/sample - loss: 0.4073 - acc: 0.8396 - val_loss: 0.4271 - val_acc: 0.8287\n",
            "Epoch 140/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4075 - acc: 0.8433\n",
            "Epoch 00140: val_loss improved from 0.42335 to 0.42303, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 3s 347us/sample - loss: 0.4073 - acc: 0.8434 - val_loss: 0.4230 - val_acc: 0.8322\n",
            "Epoch 141/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4065 - acc: 0.8397\n",
            "Epoch 00141: val_loss improved from 0.42303 to 0.42171, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 315us/sample - loss: 0.4063 - acc: 0.8399 - val_loss: 0.4217 - val_acc: 0.8300\n",
            "Epoch 142/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4079 - acc: 0.8384\n",
            "Epoch 00142: val_loss did not improve from 0.42171\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.4076 - acc: 0.8388 - val_loss: 0.4226 - val_acc: 0.8322\n",
            "Epoch 143/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4054 - acc: 0.8390\n",
            "Epoch 00143: val_loss did not improve from 0.42171\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4055 - acc: 0.8391 - val_loss: 0.4231 - val_acc: 0.8306\n",
            "Epoch 144/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4072 - acc: 0.8411\n",
            "Epoch 00144: val_loss did not improve from 0.42171\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.4073 - acc: 0.8411 - val_loss: 0.4231 - val_acc: 0.8259\n",
            "Epoch 145/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4056 - acc: 0.8411\n",
            "Epoch 00145: val_loss improved from 0.42171 to 0.42069, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 3s 353us/sample - loss: 0.4062 - acc: 0.8404 - val_loss: 0.4207 - val_acc: 0.8311\n",
            "Epoch 146/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4083 - acc: 0.8388\n",
            "Epoch 00146: val_loss did not improve from 0.42069\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.4064 - acc: 0.8402 - val_loss: 0.4286 - val_acc: 0.8292\n",
            "Epoch 147/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4055 - acc: 0.8403\n",
            "Epoch 00147: val_loss did not improve from 0.42069\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4045 - acc: 0.8407 - val_loss: 0.4220 - val_acc: 0.8309\n",
            "Epoch 148/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4030 - acc: 0.8423\n",
            "Epoch 00148: val_loss did not improve from 0.42069\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.4039 - acc: 0.8416 - val_loss: 0.4214 - val_acc: 0.8322\n",
            "Epoch 149/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4044 - acc: 0.8397\n",
            "Epoch 00149: val_loss did not improve from 0.42069\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4051 - acc: 0.8396 - val_loss: 0.4227 - val_acc: 0.8295\n",
            "Epoch 150/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4050 - acc: 0.8386\n",
            "Epoch 00150: val_loss improved from 0.42069 to 0.41988, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 3s 343us/sample - loss: 0.4046 - acc: 0.8386 - val_loss: 0.4199 - val_acc: 0.8333\n",
            "Epoch 151/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4034 - acc: 0.8402\n",
            "Epoch 00151: val_loss improved from 0.41988 to 0.41941, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 311us/sample - loss: 0.4034 - acc: 0.8400 - val_loss: 0.4194 - val_acc: 0.8309\n",
            "Epoch 152/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4031 - acc: 0.8392\n",
            "Epoch 00152: val_loss did not improve from 0.41941\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4030 - acc: 0.8394 - val_loss: 0.4225 - val_acc: 0.8290\n",
            "Epoch 153/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4045 - acc: 0.8405\n",
            "Epoch 00153: val_loss improved from 0.41941 to 0.41899, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 312us/sample - loss: 0.4035 - acc: 0.8417 - val_loss: 0.4190 - val_acc: 0.8317\n",
            "Epoch 154/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4040 - acc: 0.8377\n",
            "Epoch 00154: val_loss did not improve from 0.41899\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4038 - acc: 0.8380 - val_loss: 0.4286 - val_acc: 0.8292\n",
            "Epoch 155/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4032 - acc: 0.8417\n",
            "Epoch 00155: val_loss did not improve from 0.41899\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.4030 - acc: 0.8420 - val_loss: 0.4218 - val_acc: 0.8292\n",
            "Epoch 156/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4003 - acc: 0.8424\n",
            "Epoch 00156: val_loss improved from 0.41899 to 0.41871, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.4009 - acc: 0.8416 - val_loss: 0.4187 - val_acc: 0.8350\n",
            "Epoch 157/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4025 - acc: 0.8409\n",
            "Epoch 00157: val_loss did not improve from 0.41871\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4027 - acc: 0.8408 - val_loss: 0.4206 - val_acc: 0.8259\n",
            "Epoch 158/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4021 - acc: 0.8393\n",
            "Epoch 00158: val_loss did not improve from 0.41871\n",
            "7308/7308 [==============================] - 2s 310us/sample - loss: 0.4019 - acc: 0.8396 - val_loss: 0.4190 - val_acc: 0.8342\n",
            "Epoch 159/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4013 - acc: 0.8414\n",
            "Epoch 00159: val_loss did not improve from 0.41871\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.4012 - acc: 0.8415 - val_loss: 0.4203 - val_acc: 0.8311\n",
            "Epoch 160/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4010 - acc: 0.8417\n",
            "Epoch 00160: val_loss improved from 0.41871 to 0.41760, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 3s 344us/sample - loss: 0.4009 - acc: 0.8418 - val_loss: 0.4176 - val_acc: 0.8314\n",
            "Epoch 161/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4016 - acc: 0.8416\n",
            "Epoch 00161: val_loss did not improve from 0.41760\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.4004 - acc: 0.8422 - val_loss: 0.4226 - val_acc: 0.8300\n",
            "Epoch 162/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.4012 - acc: 0.8422\n",
            "Epoch 00162: val_loss did not improve from 0.41760\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.4011 - acc: 0.8422 - val_loss: 0.4277 - val_acc: 0.8290\n",
            "Epoch 163/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3999 - acc: 0.8416\n",
            "Epoch 00163: val_loss improved from 0.41760 to 0.41697, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 337us/sample - loss: 0.4001 - acc: 0.8415 - val_loss: 0.4170 - val_acc: 0.8325\n",
            "Epoch 164/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3997 - acc: 0.8424\n",
            "Epoch 00164: val_loss did not improve from 0.41697\n",
            "7308/7308 [==============================] - 2s 312us/sample - loss: 0.3997 - acc: 0.8426 - val_loss: 0.4253 - val_acc: 0.8298\n",
            "Epoch 165/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4021 - acc: 0.8408\n",
            "Epoch 00165: val_loss did not improve from 0.41697\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.4022 - acc: 0.8407 - val_loss: 0.4174 - val_acc: 0.8347\n",
            "Epoch 166/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.3997 - acc: 0.8411\n",
            "Epoch 00166: val_loss did not improve from 0.41697\n",
            "7308/7308 [==============================] - 2s 313us/sample - loss: 0.3989 - acc: 0.8417 - val_loss: 0.4344 - val_acc: 0.8295\n",
            "Epoch 167/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4027 - acc: 0.8395\n",
            "Epoch 00167: val_loss did not improve from 0.41697\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4024 - acc: 0.8397 - val_loss: 0.4198 - val_acc: 0.8309\n",
            "Epoch 168/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.4008 - acc: 0.8420\n",
            "Epoch 00168: val_loss did not improve from 0.41697\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4001 - acc: 0.8426 - val_loss: 0.4171 - val_acc: 0.8350\n",
            "Epoch 169/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3992 - acc: 0.8434\n",
            "Epoch 00169: val_loss improved from 0.41697 to 0.41673, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 340us/sample - loss: 0.3997 - acc: 0.8433 - val_loss: 0.4167 - val_acc: 0.8352\n",
            "Epoch 170/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.3990 - acc: 0.8411\n",
            "Epoch 00170: val_loss did not improve from 0.41673\n",
            "7308/7308 [==============================] - 2s 311us/sample - loss: 0.3986 - acc: 0.8413 - val_loss: 0.4241 - val_acc: 0.8298\n",
            "Epoch 171/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.3995 - acc: 0.8391\n",
            "Epoch 00171: val_loss did not improve from 0.41673\n",
            "7308/7308 [==============================] - 2s 315us/sample - loss: 0.3981 - acc: 0.8396 - val_loss: 0.4297 - val_acc: 0.8292\n",
            "Epoch 172/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4006 - acc: 0.8403\n",
            "Epoch 00172: val_loss did not improve from 0.41673\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.4001 - acc: 0.8409 - val_loss: 0.4247 - val_acc: 0.8292\n",
            "Epoch 173/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.4018 - acc: 0.8411\n",
            "Epoch 00173: val_loss improved from 0.41673 to 0.41586, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 338us/sample - loss: 0.4024 - acc: 0.8397 - val_loss: 0.4159 - val_acc: 0.8270\n",
            "Epoch 174/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3984 - acc: 0.8424\n",
            "Epoch 00174: val_loss did not improve from 0.41586\n",
            "7308/7308 [==============================] - 2s 304us/sample - loss: 0.3987 - acc: 0.8421 - val_loss: 0.4173 - val_acc: 0.8317\n",
            "Epoch 175/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.4000 - acc: 0.8413\n",
            "Epoch 00175: val_loss did not improve from 0.41586\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.3990 - acc: 0.8422 - val_loss: 0.4271 - val_acc: 0.8284\n",
            "Epoch 176/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.3993 - acc: 0.8422\n",
            "Epoch 00176: val_loss improved from 0.41586 to 0.41534, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 338us/sample - loss: 0.3988 - acc: 0.8424 - val_loss: 0.4153 - val_acc: 0.8270\n",
            "Epoch 177/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.3981 - acc: 0.8410\n",
            "Epoch 00177: val_loss did not improve from 0.41534\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.3977 - acc: 0.8409 - val_loss: 0.4169 - val_acc: 0.8320\n",
            "Epoch 178/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.3973 - acc: 0.8409\n",
            "Epoch 00178: val_loss did not improve from 0.41534\n",
            "7308/7308 [==============================] - 2s 304us/sample - loss: 0.3967 - acc: 0.8414 - val_loss: 0.4246 - val_acc: 0.8292\n",
            "Epoch 179/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.3962 - acc: 0.8456\n",
            "Epoch 00179: val_loss did not improve from 0.41534\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.3980 - acc: 0.8449 - val_loss: 0.4193 - val_acc: 0.8320\n",
            "Epoch 180/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.3976 - acc: 0.8428\n",
            "Epoch 00180: val_loss did not improve from 0.41534\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.3979 - acc: 0.8426 - val_loss: 0.4208 - val_acc: 0.8320\n",
            "Epoch 181/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.3953 - acc: 0.8426\n",
            "Epoch 00181: val_loss did not improve from 0.41534\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.3962 - acc: 0.8415 - val_loss: 0.4194 - val_acc: 0.8205\n",
            "Epoch 182/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.3987 - acc: 0.8408\n",
            "Epoch 00182: val_loss did not improve from 0.41534\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.3975 - acc: 0.8411 - val_loss: 0.4159 - val_acc: 0.8322\n",
            "Epoch 183/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.3986 - acc: 0.8398\n",
            "Epoch 00183: val_loss improved from 0.41534 to 0.41439, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 336us/sample - loss: 0.3971 - acc: 0.8404 - val_loss: 0.4144 - val_acc: 0.8265\n",
            "Epoch 184/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3969 - acc: 0.8420\n",
            "Epoch 00184: val_loss improved from 0.41439 to 0.41380, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.3971 - acc: 0.8420 - val_loss: 0.4138 - val_acc: 0.8355\n",
            "Epoch 185/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.3952 - acc: 0.8450\n",
            "Epoch 00185: val_loss did not improve from 0.41380\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.3951 - acc: 0.8443 - val_loss: 0.4156 - val_acc: 0.8322\n",
            "Epoch 186/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.3964 - acc: 0.8414\n",
            "Epoch 00186: val_loss improved from 0.41380 to 0.41315, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.3961 - acc: 0.8417 - val_loss: 0.4132 - val_acc: 0.8328\n",
            "Epoch 187/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3947 - acc: 0.8446\n",
            "Epoch 00187: val_loss did not improve from 0.41315\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.3946 - acc: 0.8445 - val_loss: 0.4134 - val_acc: 0.8355\n",
            "Epoch 188/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.3961 - acc: 0.8417\n",
            "Epoch 00188: val_loss did not improve from 0.41315\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.3962 - acc: 0.8415 - val_loss: 0.4132 - val_acc: 0.8358\n",
            "Epoch 189/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.3937 - acc: 0.8448\n",
            "Epoch 00189: val_loss did not improve from 0.41315\n",
            "7308/7308 [==============================] - 2s 304us/sample - loss: 0.3944 - acc: 0.8445 - val_loss: 0.4209 - val_acc: 0.8295\n",
            "Epoch 190/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.3922 - acc: 0.8442\n",
            "Epoch 00190: val_loss improved from 0.41315 to 0.41260, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.3943 - acc: 0.8430 - val_loss: 0.4126 - val_acc: 0.8339\n",
            "Epoch 191/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3957 - acc: 0.8431\n",
            "Epoch 00191: val_loss did not improve from 0.41260\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.3954 - acc: 0.8433 - val_loss: 0.4140 - val_acc: 0.8339\n",
            "Epoch 192/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3947 - acc: 0.8413\n",
            "Epoch 00192: val_loss did not improve from 0.41260\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.3944 - acc: 0.8415 - val_loss: 0.4194 - val_acc: 0.8317\n",
            "Epoch 193/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3941 - acc: 0.8461\n",
            "Epoch 00193: val_loss did not improve from 0.41260\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.3940 - acc: 0.8462 - val_loss: 0.4138 - val_acc: 0.8342\n",
            "Epoch 194/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.3952 - acc: 0.8422\n",
            "Epoch 00194: val_loss did not improve from 0.41260\n",
            "7308/7308 [==============================] - 2s 304us/sample - loss: 0.3947 - acc: 0.8421 - val_loss: 0.4137 - val_acc: 0.8339\n",
            "Epoch 195/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.3944 - acc: 0.8435\n",
            "Epoch 00195: val_loss did not improve from 0.41260\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.3934 - acc: 0.8440 - val_loss: 0.4147 - val_acc: 0.8333\n",
            "Epoch 196/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.3926 - acc: 0.8433\n",
            "Epoch 00196: val_loss improved from 0.41260 to 0.41169, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 339us/sample - loss: 0.3943 - acc: 0.8424 - val_loss: 0.4117 - val_acc: 0.8333\n",
            "Epoch 197/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.3938 - acc: 0.8433\n",
            "Epoch 00197: val_loss did not improve from 0.41169\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.3932 - acc: 0.8433 - val_loss: 0.4151 - val_acc: 0.8243\n",
            "Epoch 198/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.3923 - acc: 0.8455\n",
            "Epoch 00198: val_loss improved from 0.41169 to 0.41152, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 311us/sample - loss: 0.3928 - acc: 0.8452 - val_loss: 0.4115 - val_acc: 0.8342\n",
            "Epoch 199/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3924 - acc: 0.8424\n",
            "Epoch 00199: val_loss did not improve from 0.41152\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.3927 - acc: 0.8422 - val_loss: 0.4129 - val_acc: 0.8350\n",
            "Epoch 200/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.3917 - acc: 0.8454\n",
            "Epoch 00200: val_loss did not improve from 0.41152\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.3932 - acc: 0.8446 - val_loss: 0.4131 - val_acc: 0.8339\n",
            "Epoch 201/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3938 - acc: 0.8445\n",
            "Epoch 00201: val_loss did not improve from 0.41152\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.3935 - acc: 0.8446 - val_loss: 0.4126 - val_acc: 0.8273\n",
            "Epoch 202/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.3934 - acc: 0.8424\n",
            "Epoch 00202: val_loss improved from 0.41152 to 0.41103, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 331us/sample - loss: 0.3932 - acc: 0.8426 - val_loss: 0.4110 - val_acc: 0.8331\n",
            "Epoch 203/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.3938 - acc: 0.8420\n",
            "Epoch 00203: val_loss improved from 0.41103 to 0.41073, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 311us/sample - loss: 0.3937 - acc: 0.8420 - val_loss: 0.4107 - val_acc: 0.8344\n",
            "Epoch 204/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.3951 - acc: 0.8415\n",
            "Epoch 00204: val_loss did not improve from 0.41073\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.3939 - acc: 0.8419 - val_loss: 0.4126 - val_acc: 0.8347\n",
            "Epoch 205/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3937 - acc: 0.8442\n",
            "Epoch 00205: val_loss did not improve from 0.41073\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.3936 - acc: 0.8443 - val_loss: 0.4144 - val_acc: 0.8342\n",
            "Epoch 206/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.3935 - acc: 0.8462\n",
            "Epoch 00206: val_loss did not improve from 0.41073\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.3928 - acc: 0.8465 - val_loss: 0.4109 - val_acc: 0.8290\n",
            "Epoch 207/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3931 - acc: 0.8420\n",
            "Epoch 00207: val_loss did not improve from 0.41073\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.3928 - acc: 0.8422 - val_loss: 0.4128 - val_acc: 0.8270\n",
            "Epoch 208/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3920 - acc: 0.8433\n",
            "Epoch 00208: val_loss did not improve from 0.41073\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.3917 - acc: 0.8435 - val_loss: 0.4117 - val_acc: 0.8355\n",
            "Epoch 209/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3906 - acc: 0.8438\n",
            "Epoch 00209: val_loss improved from 0.41073 to 0.41000, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 337us/sample - loss: 0.3906 - acc: 0.8437 - val_loss: 0.4100 - val_acc: 0.8336\n",
            "Epoch 210/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.3918 - acc: 0.8453\n",
            "Epoch 00210: val_loss did not improve from 0.41000\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.3918 - acc: 0.8450 - val_loss: 0.4119 - val_acc: 0.8270\n",
            "Epoch 211/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.3925 - acc: 0.8414\n",
            "Epoch 00211: val_loss did not improve from 0.41000\n",
            "7308/7308 [==============================] - 2s 304us/sample - loss: 0.3913 - acc: 0.8420 - val_loss: 0.4209 - val_acc: 0.8320\n",
            "Epoch 212/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.3909 - acc: 0.8440\n",
            "Epoch 00212: val_loss did not improve from 0.41000\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.3908 - acc: 0.8439 - val_loss: 0.4138 - val_acc: 0.8339\n",
            "Epoch 213/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.3917 - acc: 0.8438\n",
            "Epoch 00213: val_loss did not improve from 0.41000\n",
            "7308/7308 [==============================] - 2s 305us/sample - loss: 0.3920 - acc: 0.8442 - val_loss: 0.4351 - val_acc: 0.8281\n",
            "Epoch 214/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3927 - acc: 0.8457\n",
            "Epoch 00214: val_loss improved from 0.41000 to 0.40933, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 333us/sample - loss: 0.3926 - acc: 0.8456 - val_loss: 0.4093 - val_acc: 0.8347\n",
            "Epoch 215/1000\n",
            "7232/7308 [============================>.] - ETA: 0s - loss: 0.3919 - acc: 0.8426\n",
            "Epoch 00215: val_loss improved from 0.40933 to 0.40926, saving model to /content/gdrive/My Drive/model/Xray_img_classification.model\n",
            "7308/7308 [==============================] - 2s 310us/sample - loss: 0.3910 - acc: 0.8430 - val_loss: 0.4093 - val_acc: 0.8331\n",
            "Epoch 216/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3912 - acc: 0.8440\n",
            "Epoch 00216: val_loss did not improve from 0.40926\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.3911 - acc: 0.8441 - val_loss: 0.4095 - val_acc: 0.8358\n",
            "Epoch 217/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.3913 - acc: 0.8435\n",
            "Epoch 00217: val_loss did not improve from 0.40926\n",
            "7308/7308 [==============================] - 2s 308us/sample - loss: 0.3892 - acc: 0.8450 - val_loss: 0.4298 - val_acc: 0.8292\n",
            "Epoch 218/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3904 - acc: 0.8433\n",
            "Epoch 00218: val_loss did not improve from 0.40926\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.3902 - acc: 0.8434 - val_loss: 0.4095 - val_acc: 0.8298\n",
            "Epoch 219/1000\n",
            "7296/7308 [============================>.] - ETA: 0s - loss: 0.3887 - acc: 0.8431\n",
            "Epoch 00219: val_loss did not improve from 0.40926\n",
            "7308/7308 [==============================] - 2s 306us/sample - loss: 0.3891 - acc: 0.8428 - val_loss: 0.4182 - val_acc: 0.8325\n",
            "Epoch 220/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.3892 - acc: 0.8453\n",
            "Epoch 00220: val_loss did not improve from 0.40926\n",
            "7308/7308 [==============================] - 2s 309us/sample - loss: 0.3892 - acc: 0.8450 - val_loss: 0.4137 - val_acc: 0.8333\n",
            "Epoch 221/1000\n",
            "7104/7308 [============================>.] - ETA: 0s - loss: 0.3907 - acc: 0.8425\n",
            "Epoch 00221: val_loss did not improve from 0.40926\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.3893 - acc: 0.8436 - val_loss: 0.4229 - val_acc: 0.8303\n",
            "Epoch 222/1000\n",
            "7168/7308 [============================>.] - ETA: 0s - loss: 0.3919 - acc: 0.8442\n",
            "Epoch 00222: val_loss did not improve from 0.40926\n",
            "7308/7308 [==============================] - 2s 307us/sample - loss: 0.3904 - acc: 0.8454 - val_loss: 0.4180 - val_acc: 0.8325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ95U2WF7Rdf",
        "colab_type": "text"
      },
      "source": [
        "# 7. 모델 테스트\n",
        "test set으로 모델의 성능을 테스트 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BahTqwB0X9o",
        "colab_type": "code",
        "outputId": "33db4c34-e5f1-4202-8f8a-ab37457c2d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(\"정확도 : %.4f\" % (model.evaluate(testX, testY)[1]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2282/2282 [==============================] - 1s 265us/sample - loss: 0.4029 - acc: 0.8339\n",
            "정확도 : 0.8339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R1l8P297ZBs",
        "colab_type": "text"
      },
      "source": [
        "# 8. 학습 과정\n",
        "모델의 학습 과정을 그래프로 도사한다.<br>\n",
        "train_loss는 점점 감소하지만 val_loss는 어느 순간 잘 감소하지 않고 오히려 증가하는 것을 볼 수 있다.<br>\n",
        "따라서 overfitting이 일어나기 전에 checkpoint에서 학습을 중지한 것을 볼 수 있다.<br>\n",
        "(밑의 그래프는 ResNet50을 사용한 전이 학습 과정이다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAhuwYdU0ZNn",
        "colab_type": "code",
        "outputId": "c29242ce-01bc-49f2-995f-cc404b8c586d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "x_len = np.arange(len(y_loss))\n",
        "\n",
        "font = {'weight' : '600',\n",
        "        'size'   : 17}\n",
        "plt.rc('font', **font)\n",
        "plt.rcParams['text.color'] = 'black'\n",
        "plt.rcParams['axes.labelcolor'] = 'grey'\n",
        "plt.rcParams['axes.labelweight'] = '600'\n",
        "plt.rcParams['xtick.color'] = 'grey'\n",
        "plt.rcParams['ytick.color'] = 'grey'\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(x_len, y_vloss, marker='.', c='red', label='val_set_loss')\n",
        "plt.plot(x_len, y_loss, marker='.', c='blue', label='train_set_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()\n",
        "plt.annotate('checkpoint',xy=(len(y_vloss)-8,y_vloss[len(y_vloss)-8]),xytext=(len(y_vloss)-10,y_vloss[len(y_vloss)-8]*1.1),arrowprops={'color':'green'},)\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr4AAAJdCAYAAADUV3RZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7L573iJJdNK",
        "colab_type": "text"
      },
      "source": [
        "# 9. Review\n",
        "폐렴 사진은 5704장 뿐인데 정상 사진은 약 6만개가 넘었다.<br>\n",
        "따라서 랜덤하게 정상 사진에서 5704개의 사진을 두 그룹으로 뽑았다.(A그룹, B그룹)<br>\n",
        "정상, 폐렴 각각 5704장의 사진중에서 랜덤하게 20%(1141장)의 사진을 test set을 위해 분리했다.<br>\n",
        "A그룹의 정상 사진과 폐렴 사진을 사용한 모델은 평균적으로 88%의 정확도를 나타냈다.<br>\n",
        "B그룹의 정상 사진과 폐렴 사진을 사용한 모델은 평균적으로 85%의 정확도를 나타냈다.<br>\n",
        "모델의 평균 정확도는 약 86% 정도로 볼 수 있으므로 꽤 유능한 분류 성능을 보여준다.<br>\n",
        "<br>\n",
        "기존 분류모델인 VGG16, Inception V3, ResNet50을 특징 추출기로 사용하여 전이 학습(transfer learning)을 해봤지만<br> \n",
        "오히려 성능은 낮게 나왔다.(전이 학습을 한 모델이 비슷한 정확도지만 loss값이 더 높았다)<br>\n",
        "따라서 직접 설계한 간단한 CNN 모델이 더 좋다고 생각한다.<br>\n",
        "<br>\n",
        "### 전이 학습에 히트맵이 없는 이유\n",
        "히트맵을 만들려면 특징 추출의 마지막 층을 분류기의 출력 층으로 미분하여 gradients 값을 구해야 되는데,<br>\n",
        "전이 학습을 사용한 모델은 특징 추출기가 가중치를 동결시키고 분류기와 연결시켜서<br> \n",
        "두 layer사이에 gradients가 연관되어있지 않아서 히트맵을 만들 수 없었다."
      ]
    }
  ]
}